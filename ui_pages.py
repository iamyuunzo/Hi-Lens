# ui_pages.py â€” ìµœì¢…ë³¸ (ìš”ì²­ì‚¬í•­ ëª¨ë‘ ë°˜ì˜)
# -----------------------------------------------------------------------------
# âœ… ë°˜ì˜ì‚¬í•­:
#   - ëŒ€í™” íƒ­/í‘œÂ·ê·¸ë¦¼ íƒ­ ëª¨ë‘ ë™ì¼í•œ st.chat_input ê¸°ë°˜ AI ì±—ë´‡ UI
#     Â· ëŒ€í™” íƒ­: ì „ì²´ ì›ë¬¸ QA
#     Â· í‘œÂ·ê·¸ë¦¼ íƒ­: í‘œ/ê·¸ë¦¼ ì¤‘ì‹¬ QA (í‘œ ë¯¸ë¦¬ë³´ê¸°/ì¸ì ‘ë³¸ë¬¸ì— í•œì •)
#   - ì¶”ì²œì§ˆë¬¸/ëª©ì°¨ í† ê¸€/ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ë³´ì¡´
#   - ì´ë¯¸ì§€: max-width ì œí•œ(ê¸°ë³¸ 800px) + ë°˜ì‘í˜•(use_container_width=True)
#   - ëœë”©: ì œëª©/ì„¤ëª… ì„¼í„° ì •ë ¬
#   - ë¡œë”©: ìŠ¤í”¼ë„ˆ/ì œëª©/ì§„í–‰ë°” ê°„ê²© ì¡°ì •
#   - ë‹µë³€/ê·¼ê±°/ìš”ì•½: ë¬¸ì¥ ì¤„ë°”ê¿ˆ + ë¶ˆë¦¿(â—¦)
# -----------------------------------------------------------------------------
APP_VERSION = "2025-09-26.01"

from __future__ import annotations
import time, hashlib, datetime as dt, re
from typing import Dict, Any, List, Optional

import pandas as pd
import streamlit as st
from styles import get_css, ACCENT
from extract import build_chunks, crop_table_image
try:
    from extract import crop_figure_image
except Exception:
    crop_figure_image = crop_table_image  # í´ë°±

# LLM ìœ í‹¸ë“¤
from llm import (
    answer_with_context,
    get_provider_name,
    explain_tables,
)
# explain_figure_imageëŠ” ì˜ˆì™¸ ëŒ€ë¹„ í´ë°±
try:
    from llm import explain_figure_image
except Exception:
    def explain_figure_image(query: str, image, neighbor_text: str = "") -> str:
        return answer_with_context(
            query,
            f"[ì´ë¯¸ì§€ ìš”ì•½ í´ë°±]\n{(neighbor_text or '')[:1800]}",
            page_label=None,
        )

from summarizer import summarize_from_chunks
from qa_recos import QA_RECOMMENDATIONS
from rag import RAGIndex
try:
    from rank_bm25 import BM25Okapi
except Exception:
    BM25Okapi = None


# ================================ ì„¸ì…˜/ìœ í‹¸ ================================
def _init_session_defaults():
    """ì•± ì „ì—­ ì„¸ì…˜í‚¤ ê¸°ë³¸ê°’"""
    st.session_state.setdefault("route", "landing")
    st.session_state.setdefault("pdf_bytes", None)
    st.session_state.setdefault("pdf_name", "")
    st.session_state.setdefault("chunks", {})
    st.session_state.setdefault("summary", "")
    st.session_state.setdefault("chat", [])          # ëŒ€í™” íƒ­ íˆìŠ¤í† ë¦¬
    st.session_state.setdefault("toc_dialogs", [])   # í‘œÂ·ê·¸ë¦¼ íƒ­ íˆìŠ¤í† ë¦¬
    st.session_state.setdefault("_threads", [])
    st.session_state.setdefault("_current_tid", None)


def _pdf_id() -> Optional[str]:
    """ì—…ë¡œë“œ PDFë¥¼ í•´ì‹œë¡œ ì‹ë³„"""
    data = st.session_state.get("pdf_bytes")
    return hashlib.sha1(data).hexdigest()[:12] if data else None


def _threads() -> List[Dict[str, Any]]:
    """ë¬¸ì„œë³„ ì„¸ì…˜ ì €ì¥ì†Œ"""
    return st.session_state.setdefault("_threads", [])


def _current_thread() -> Optional[Dict[str, Any]]:
    tid = st.session_state.get("_current_tid")
    for t in _threads():
        if t["tid"] == tid:
            return t
    return None


def _ensure_thread():
    """í˜„ì¬ PDF ê¸°ì¤€ ìŠ¤ë ˆë“œ ì—†ìœ¼ë©´ ìƒì„±"""
    if _current_thread():
        return
    pid = _pdf_id()
    name = st.session_state.get("pdf_name") or "ë¬¸ì„œ"
    tid = f"{pid}-{int(time.time())}"
    _threads().append(
        {"tid": tid, "pdf_id": pid, "pdf_name": name, "ts": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
         "messages": [], "pdf_bytes": st.session_state.get("pdf_bytes"), "chunks": {}, "summary": ""}
    )
    st.session_state["_current_tid"] = tid


# ================================ ì‚¬ì´ë“œë°” ================================
def render_sidebar():
    st.sidebar.markdown("<div class='hp-brand'><span class='dot'></span>Hi-Lens</div>", unsafe_allow_html=True)
    st.sidebar.caption("PDF ìš”ì•½Â·ë°œì·ŒÂ·ì‹œê°í™” ë„ìš°ë¯¸")
    st.sidebar.info(f"LLM: {get_provider_name()}", icon="ğŸ§ ")

    if st.sidebar.button("ğŸ  í™ˆìœ¼ë¡œ", use_container_width=True):
        st.session_state["route"] = "landing"; st.rerun()

    st.sidebar.markdown("---")
    st.sidebar.subheader("PDF ë¶„ì„ ê¸°ë¡")

    for t in reversed(_threads()):
        label = f"ğŸ“„ {t['pdf_name']} Â· {t['ts']} Â· ì§ˆë¬¸ {len(t['messages'])}ê°œ"
        if st.sidebar.button(label, key=f"hist-{t['tid']}", use_container_width=True):
            st.session_state.update(
                {"_current_tid": t["tid"], "pdf_name": t["pdf_name"], "pdf_bytes": t.get("pdf_bytes"),
                 "chunks": t.get("chunks", {}), "summary": t.get("summary", ""), "route": "analysis"}
            ); st.rerun()


# ================================ í˜ì´ì§€ë“¤ ================================
def landing_page():
    _init_session_defaults()
    _inject_css()
    render_sidebar()

    # ì œëª©/ì„¤ëª… ëª¨ë‘ ì„¼í„° ì •ë ¬
    st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
    st.markdown("<h1 style='font-weight:900; text-align:center;'>ğŸ‘‹ Hi-Lens</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center;'>PDFì—ì„œ í‘œ/ê·¸ë¦¼/ë¬¸ë‹¨ì„ ì¶”ì¶œí•´ <b>ì§ˆë¬¸ â†’ í‘œ/ê·¸ë˜í”„/ìš”ì•½</b>ìœ¼ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.</p>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)

    upl = st.file_uploader("ë¶„ì„í•  PDF ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", type=["pdf"], key="landing_upl")
    if st.button("ğŸ” ë¶„ì„ ì‹œì‘", use_container_width=True):
        if not upl:
            st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."); st.stop()
        pdf_bytes, pdf_name = upl.read(), upl.name
        pdf_id = hashlib.sha1(pdf_bytes).hexdigest()[:12]
        tid = f"{pdf_id}-{int(time.time())}"
        _threads().append({"tid": tid, "pdf_id": pdf_id, "pdf_name": pdf_name,
                           "ts": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
                           "messages": [], "pdf_bytes": pdf_bytes, "chunks": {}, "summary": ""})
        st.session_state.update({"_current_tid": tid, "pdf_bytes": pdf_bytes, "pdf_name": pdf_name, "route": "loading"})
        st.rerun()


def loading_page():
    _init_session_defaults()

    # í—¤ë”/ì‚¬ì´ë“œë°” ìˆ¨ê¹€
    st.markdown("<style>section[data-testid='stSidebar']{display:none;} header,footer{display:none;}</style>", unsafe_allow_html=True)

    # ğŸ”§ í”„ë¡œê·¸ë ˆìŠ¤ë°” ìƒ‰ìƒ ê°•ì œ ë³€ê²½ (ê¸°ë³¸ ë¹¨ê°• â†’ ë‚¨ìƒ‰)
    st.markdown(
        """
        <style>
          /* ì§„í–‰ ë°” ì±„ì›Œì§€ëŠ” ë¶€ë¶„ ìƒ‰ìƒ */
          .stProgress > div > div > div > div {
              background-color: #0f2e69 !important;
          }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ë¡œë”© ìŠ¤í”¼ë„ˆ + ê°„ê²© (ğŸ”§ ê°„ê²© í™•ì¥)
    st.markdown(
        """
        <style>
          .hl-wrap { text-align:center; margin-top:110px; /* ğŸ”§ ìƒë‹¨ ì—¬ë°± í™•ëŒ€ */ }
          .hl-spinner {
            margin: 0 auto 34px auto; /* ğŸ”§ ìŠ¤í”¼ë„ˆì™€ ì œëª© ì‚¬ì´ ê°„ê²© í™•ëŒ€ */ width: 42px; height: 42px;
            border: 4px solid #e9ecef; border-top-color: #dc8d32;
            border-radius: 50%; animation: hlspin .9s linear infinite;
          }
          @keyframes hlspin { to { transform: rotate(360deg); } }
          .hl-title { font-weight: 900; font-size: 28px; margin-bottom: 28px; /* ğŸ”§ ì œëª©ê³¼ ì§„í–‰ë°” ì‚¬ì´ ê°„ê²© í™•ëŒ€ */ }
        </style>
        <div class="hl-wrap">
          <div class="hl-spinner"></div>
          <div class="hl-title">Hi-Lensê°€ ë¶„ì„ì¤‘...</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    st.markdown("<div style='height:25px'></div>", unsafe_allow_html=True)  # ğŸ”§ ìŠ¤í”¼ë„ˆ/ì œëª©ê³¼ ë¡œë”©ë°” ì‚¬ì´ ê°„ê²© í™•ë³´
    bar = st.progress(0.0, text="PDF ì²˜ë¦¬ ì‹œì‘")
    pdf_bytes = st.session_state.get("pdf_bytes")
    if not pdf_bytes:
        st.warning("ì—…ë¡œë“œëœ PDFê°€ ì—†ìŠµë‹ˆë‹¤."); return

    # ì‹¤ì œ ì¶”ì¶œ/ìš”ì•½
    chunks = build_chunks(pdf_bytes)
    def _cb(msg, ratio): bar.progress(ratio, text=msg)
    summary = summarize_from_chunks(chunks, max_pages=20, progress_cb=_cb)

    # ì„¸ì…˜ ì €ì¥
    st.session_state["chunks"], st.session_state["summary"] = chunks, summary
    th = _current_thread()
    if th: th.update({"chunks": chunks, "summary": summary})

    st.session_state["route"] = "analysis"; st.rerun()


def analysis_page():
    _init_session_defaults()

    # âœ… ë°°í¬í•  ë•Œë§ˆë‹¤ ìºì‹œ ì‹¹ ë¹„ìš°ê¸°
    st.cache_data.clear()
    st.cache_resource.clear()
    
    _inject_css()
    render_sidebar()

    pdf_name = st.session_state.get("pdf_name") or "ë¶„ì„ ë¬¸ì„œ"
    chunks   = st.session_state.get("chunks") or {}
    summary  = st.session_state.get("summary") or ""
    _ensure_thread()

    n_t, n_f, n_x = len(chunks.get("tables", [])), len(chunks.get("figures", [])), len(chunks.get("texts", []))
    st.markdown(
        f"<div class='hp-header'><div class='title'>ğŸ“„ {pdf_name}</div>"
        f"<div class='summary'>í…ìŠ¤íŠ¸ {n_x} Â· í‘œ {n_t} Â· ê·¸ë¦¼ {n_f}</div></div>",
        unsafe_allow_html=True
    )

    # ================== íƒ­ ==================
    tab_chat, tab_toc = st.tabs(["ğŸ’¬ ëŒ€í™”", "ğŸ“‘ í‘œÂ·ê·¸ë¦¼ ëª©ì°¨"])

    # ----------------------- ëŒ€í™” íƒ­ -----------------------
    with tab_chat:
        with st.expander("ì›ë¬¸ ìš”ì•½", expanded=False):
            if summary:
                summary_fmt = _format_paragraphs(summary, bullets=True)
                st.markdown(f"<div class='hp-answer-box1'>{summary_fmt}</div>", unsafe_allow_html=True)
            else:
                st.info("ìš”ì•½ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        with st.expander("ì¶”ì²œ ì§ˆë¬¸", expanded=False):
            recos = QA_RECOMMENDATIONS.get(pdf_name, {})
            for i, (_, data) in enumerate(recos.items()):
                if st.button(data["question"], key=f"recbtn-{i}"):
                    _append_dialog(
                        which="chat",
                        user=data["question"],
                        answer=data["answer"],
                        grounds=data.get("grounds")
                    ); st.rerun()

        if not st.session_state.get("chat"):
            st.info("ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ì¶”ì²œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš” ğŸ™‚")
        else:
            _render_dialogs("chat")

        # âœ… ì´ íƒ­ ì „ìš© ì…ë ¥ì°½ (í‘¸í„° ê³ ì •)
        usr_q = st.chat_input("PDF ì›ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.", key="inp-chat")
        if usr_q and usr_q.strip():
            ans, grounds = _qa_pipeline(usr_q, chunks)
            _append_dialog(which="chat", user=usr_q, answer=ans, grounds=grounds)
            st.rerun()

    # ------------------- í‘œÂ·ê·¸ë¦¼ ëª©ì°¨ íƒ­ -------------------
    with tab_toc:
        with st.expander("ëª©ì°¨ ë³´ê¸°", expanded=False):
            toc_tab1, toc_tab2 = st.tabs(["í‘œ ëª©ì°¨", "ê·¸ë¦¼ ëª©ì°¨"])
            with toc_tab1:
                _render_toc_buttons(chunks.get("toc", {}).get("tables", []), kind="table", chunks=chunks, cols=2)
            with toc_tab2:
                _render_toc_buttons(chunks.get("toc", {}).get("figures", []), kind="figure", chunks=chunks, cols=2)

        if not st.session_state.get("toc_dialogs"):
            st.info("ì•„ì§ í‘œÂ·ê·¸ë¦¼ ê´€ë ¨ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ëª©ì°¨ë¥¼ í´ë¦­í•˜ê±°ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš” ğŸ™‚")
        else:
            _render_dialogs("toc")

        # âœ… ì´ íƒ­ ì „ìš© ì…ë ¥ì°½ (í‘¸í„° ê³ ì •)
        toc_q = st.chat_input("í‘œÂ·ê·¸ë¦¼ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.", key="inp-toc")
        if toc_q and toc_q.strip():
            ans, grounds = _qa_pipeline_tables_only(toc_q, chunks)
            _append_dialog(which="toc", user=toc_q, answer=ans, grounds=grounds)
            st.rerun()



# ============================ QA íŒŒì´í”„ë¼ì¸ ============================
def _qa_pipeline(query: str, chunks: Dict[str, Any]) -> (str, list):
    """ì „ì²´ ì›ë¬¸ QA: í‘œ RAG + ë³¸ë¬¸ ê²€ìƒ‰ ê²°í•©"""
    table_parts: List[str] = []
    grounds_parts: List[tuple] = []  # (snippet, page)

    rag = RAGIndex(); rag.build_from_chunks(chunks)

    # 1) í‘œ/ê·¸ë¦¼ ê´€ë ¨ ìƒìœ„ (contextë¡œë§Œ ì‚¬ìš©, ê·¼ê±°ì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ)
    table_hits = rag.search_tables(query, k=3)
    for hit in table_hits:
        title = (hit.get("title") or "").strip()
        pno   = hit.get("page_label", "?")
        prev  = (hit.get("text") or "").strip()
        nb    = _neighbor_text(chunks, hit.get("page_index", 0) + 1)
        table_parts.append(f"(í‘œ/ê·¸ë¦¼ p.{pno}) {title}\n{prev}\n{nb}")

    # 2) ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ê·¼ê±°ëŠ” ì—¬ê¸°ì„œë§Œ ì¶”ê°€)
    text_hits = _search_text_pages(query, chunks, k=3, per_len=1200)
    for h in text_hits:
        snippet_clean = _cleanup_text_for_grounds(h["snippet"])
        if snippet_clean:
            table_parts.append(f"(ë³¸ë¬¸ p.{h['page']})\n{snippet_clean}")
            grounds_parts.append((snippet_clean, h["page"]))

    # 3) ì»¨í…ìŠ¤íŠ¸ í•©ì„±
    ctx = "\n\n---\n\n".join([p for p in table_parts if p]).strip()
    if not ctx:
        ctx = "\n".join([(t.get("text") or "") for t in chunks.get("texts", [])[:3]])[:2000]

    ans = answer_with_context(query, ctx, page_label=None)

    # âœ… ì‚¬ìš©ìê°€ "í‘œ" ìš”ì²­í–ˆì„ ë•Œë§Œ í‘œ ë³€í™˜ ì‹¤í–‰
    if "í‘œ" in query:
        table_suggestion = make_table_from_text(ctx)
        if table_suggestion:
            ans += "\n\n---\n\nğŸ“Š ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ í‘œë¡œ ì •ë¦¬í•˜ë©´:\n" + table_suggestion

    return ans, grounds_parts


def _qa_pipeline_tables_only(query: str, chunks: Dict[str, Any]) -> (str, list):
    """í‘œ/ê·¸ë¦¼ ì¤‘ì‹¬ QA: í‘œ/ê·¸ë¦¼ ë¯¸ë¦¬ë³´ê¸° + ì¸ì ‘ ë³¸ë¬¸ë§Œ ì‚¬ìš©"""
    table_parts: List[str] = []
    grounds_parts: List[tuple] = []  # (snippet, page)

    rag = RAGIndex(); rag.build_from_chunks(chunks)
    hits = rag.search_tables(query, k=5)
    for hit in hits:
        title = (hit.get("title") or "").strip()
        pno   = hit.get("page_label", "?")
        prev  = (hit.get("text") or "").strip()
        nb    = _neighbor_text(chunks, hit.get("page_index", 0) + 1)
        table_parts.append(f"(í‘œ/ê·¸ë¦¼ p.{pno}) {title}\n{prev}\n{nb}")

    # ë³¸ë¬¸ Top3 ê·¼ê±°ë„ ìˆ˜ì§‘
    text_hits = _search_text_pages(query, chunks, k=3, per_len=1200)
    for h in text_hits:
        snippet_clean = _cleanup_text_for_grounds(h["snippet"])
        if snippet_clean:
            table_parts.append(f"(ë³¸ë¬¸ p.{h['page']})\n{snippet_clean}")
            grounds_parts.append((snippet_clean, h["page"]))

    ctx = "\n\n".join([p for p in table_parts if p]).strip()[:4000]
    if not ctx:
        ctx = "\n".join([(t.get("text") or "") for t in chunks.get("texts", [])[:2]])[:1500]

    ans = answer_with_context(query, ctx, page_label=None)

    # âœ… ì‚¬ìš©ìê°€ "í‘œ" ìš”ì²­í–ˆì„ ë•Œë§Œ í‘œ ë³€í™˜ ì‹¤í–‰
    if "í‘œ" in query:
        table_suggestion = make_table_from_text(ctx)
        if table_suggestion:
            ans += "\n\n---\n\nğŸ“Š ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ í‘œë¡œ ì •ë¦¬í•˜ë©´:\n" + table_suggestion

    return ans, grounds_parts


# ================================ ëŒ€í™”/ë Œë” ================================
def _append_dialog(which: str, user: str, answer: str, item: Optional[Dict] = None, grounds: Optional[str] = None):
    """ëŒ€í™”/ëª©ì°¨ íƒ­ ë©”ì‹œì§€ ì¶”ê°€"""
    key = "toc_dialogs" if (which == "toc" or item) else "chat"
    st.session_state.setdefault(key, []).append({"user": user, "answer": answer, "item": item, "grounds": grounds})


def _render_dialogs(which: str):
    dialogs = st.session_state.get("toc_dialogs" if which == "toc" else "chat", [])
    for d in dialogs:
        # ì‚¬ìš©ì ì§ˆë¬¸
        st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
        st.markdown(
            f"<div class='hp-msg user'><div class='bubble'>{d['user']}</div></div>",
            unsafe_allow_html=True
        )
        st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
        st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
        st.markdown("<div class='hp-card__title'>ğŸ¤” Hi-Lensì˜ ë‹µë³€</div>", unsafe_allow_html=True)

        # í‘œ/ê·¸ë¦¼ ë¯¸ë¦¬ë³´ê¸° (ìˆìœ¼ë©´)
        if d.get("item"):
            _render_item_preview(d["item"])

        # ë‹µë³€ ì¶œë ¥
        formatted = _format_answer(d["answer"]) if d.get("answer") else ""

        if "|" in formatted and "---" in formatted:
            # ë§ˆí¬ë‹¤ìš´ í‘œ ê°ì§€ ì‹œ â†’ Streamlit í‘œë¡œ ë³€í™˜
            st.markdown("ğŸ“Š ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ í‘œë¡œ ì •ë¦¬í•˜ë©´:")
            render_markdown_table(formatted)
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ ë‹µë³€
            st.markdown(f"<div class='hp-answer-box'>{formatted}</div>", unsafe_allow_html=True)

        # ì›ë¬¸ ê·¼ê±° ì¶œë ¥
        if d.get("grounds"):
            st.markdown("<p style='text-align:center;'> </p>", unsafe_allow_html=True)
            with st.expander("ğŸ“‘ ì›ë¬¸ ê·¼ê±° ë³´ê¸°", expanded=False):
                grounds = d["grounds"]
                blocks = []
                if isinstance(grounds, list) and all(isinstance(g, tuple) for g in grounds):
                    for i, (txt, page) in enumerate(grounds[:3], 1):  # ìµœëŒ€ 3ê°œ
                        lines = [ln.strip() for ln in txt.split("\n") if ln.strip()]
                        if len(lines) > 2:
                            preview = [lines[0], "...(ì¤‘ëµ)...", lines[-1]]
                        elif len(lines) == 2:
                            preview = [lines[0], "...(ì¤‘ëµ)...", lines[1]]
                        elif len(lines) == 1:
                            preview = [lines[0]]
                        else:
                            preview = []
                        block = f"**ì›ë¬¸ ê·¼ê±° {i}. (p.{page})**\n" + "\n".join(preview)
                        blocks.append(block)
                else:
                    grounds_text = _cleanup_text_for_grounds(str(grounds))
                    lines = [ln.strip() for ln in grounds_text.split("\n") if ln.strip()]
                    if len(lines) > 2:
                        preview = [lines[0], "...(ì¤‘ëµ)...", lines[-1]]
                    else:
                        preview = lines
                    blocks.append(f"**ì›ë¬¸ ê·¼ê±° 1.**\n" + "\n".join(preview))

                st.markdown("\n\n".join(blocks), unsafe_allow_html=True)


# ============================ ëª©ì°¨ ë²„íŠ¼/í”„ë¦¬ë·° ============================
def _render_toc_buttons(items: List[Dict[str, Any]], kind: str, chunks: Dict[str, Any], cols: int = 2):
    """ëª©ì°¨ ë²„íŠ¼(ë²ˆí˜¸+ì œëª©) â€” ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€"""
    st.markdown(
        """
        <style>
        div[data-testid="stButton"] > button {
            padding: 6px 10px !important;
            font-size: 13px !important;
            line-height: 1.35 !important;
            white-space: normal !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    if not items:
        st.info("ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    cols_container = st.columns(cols, gap="small")
    for i, it in enumerate(items):
        col = cols_container[i % cols]
        with col:
            label = it.get("label")
            title = (it.get("title") or "").strip()
            text  = f"{'í‘œ' if kind=='table' else 'ê·¸ë¦¼'} {label}" + (f". {title}" if title else "")

            if st.button(text, key=f"toc-{kind}-{label}"):
                if kind == "table":
                    t   = _find_table_full(chunks, label)
                    q   = f"<í‘œ {label}> ì„¤ëª…í•´ì¤˜"
                    ctx = (t or {}).get("preview_md") or ""
                    nb  = _neighbor_text(chunks, (t or {}).get("page", 0)) if t else ""
                    ans = answer_with_context(q, (ctx + "\n\n" + nb)[:1800], page_label=(t or {}).get("page"))
                    _append_dialog(which="toc", user=q, answer=ans,
                                   item={"kind": "table", "obj": t}, grounds=nb)
                else:
                    f   = _find_figure_full(chunks, label)
                    q   = f"<ê·¸ë¦¼ {label}> ì„¤ëª…í•´ì¤˜"
                    nb  = _neighbor_text(chunks, (f or {}).get("page", 0)) if f else ""
                    img = None
                    try:
                        if f and f.get("bbox") and st.session_state.get("pdf_bytes"):
                            img = crop_figure_image(st.session_state["pdf_bytes"], f["page"] - 1, f["bbox"], dpi=300)
                    except Exception:
                        img = None
                    ans = explain_figure_image(q, img, neighbor_text=nb)
                    _append_dialog(which="toc", user=q, answer=ans,
                                   item={"kind": "figure", "obj": f}, grounds=nb)
                st.rerun()

        # ë‹¤ìŒ ì¤„ë¡œ ê°œí–‰
        if (i % cols) == (cols - 1) and (i != len(items) - 1):
            cols_container = st.columns(cols, gap="small")


def _render_item_preview(item: Dict[str, Any]):
    """
    í‘œ/ê·¸ë¦¼ ì¸ë„¤ì¼:
      - ì œëª©: ì´ë¯¸ì§€ 'ë°”ë¡œ ìœ„' ì¤‘ì•™/ë³¼ë“œ
      - ì´ë¯¸ì§€: ë³¸ë¬¸ í­ ì‚¬ìš© + ìµœëŒ€í­ 800px ì œí•œ(ë°˜ì‘í˜•)
    """
    if not item or "obj" not in item: return
    obj = item["obj"]; kind = item["kind"]
    if not obj: return

    # ì œëª©
    title_text = (obj.get("title") or "").strip()
    if not title_text:
        title_text = ("í‘œ" if kind == "table" else "ê·¸ë¦¼") + " " + str(obj.get("label"))
    st.markdown(f"<div class='hp-figtitle'>{title_text}</div>", unsafe_allow_html=True)

    # ì´ë¯¸ì§€ í¬ë¡­
    img = None
    try:
        if kind == "table" and obj.get("bbox") and st.session_state.get("pdf_bytes"):
            img = crop_table_image(st.session_state["pdf_bytes"], obj["page"] - 1, obj["bbox"], dpi=300)
        elif kind == "figure" and obj.get("bbox") and st.session_state.get("pdf_bytes"):
            img = crop_figure_image(st.session_state["pdf_bytes"], obj["page"] - 1, obj["bbox"], dpi=300)
    except Exception:
        img = None

    # ì´ë¯¸ì§€ í‘œì‹œ (ìµœëŒ€í­ 700px ë˜í¼ + ë°˜ì‘í˜•)
    if img is not None:
        st.markdown("<div style='max-width:400px /* ğŸ”§ ì´ë¯¸ì§€ ìµœëŒ€í­ì„ 800â†’500ìœ¼ë¡œ ì‚´ì§ ì¶•ì†Œ (ë°˜ì‘í˜• ìœ ì§€) */;margin:0 auto;'>", unsafe_allow_html=True)
        st.image(img, use_container_width=True)
        st.markdown("</div>", unsafe_allow_html=True)


# ============================== ê²€ìƒ‰ ìœ í‹¸ ==============================
def _tok(s: str) -> List[str]:
    """ê°„ë‹¨ í† í¬ë‚˜ì´ì €: í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ + ìˆ«ì(ì†Œìˆ˜/ì½¤ë§ˆ/%)"""
    return re.findall(r"[ê°€-í£A-Za-z]+|\d+(?:[.,]\d+)?%?", (s or "").lower())


def _search_text_pages(query: str, chunks: Dict[str, Any], k: int = 3, per_len: int = 1000) -> List[Dict[str, Any]]:
    """ë³¸ë¬¸ í˜ì´ì§€ ê²€ìƒ‰: BM25 ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ì ìˆ˜"""
    pages = chunks.get("texts", []) or []
    if not pages:
        return []

    docs = [p.get("text") or "" for p in pages]
    pnos = [p.get("page") for p in pages]
    qtok = _tok(query)

    # 1) BM25
    if BM25Okapi is not None:
        tokenized = [_tok(d) for d in docs]
        bm = BM25Okapi(tokenized)
        scores = bm.get_scores(qtok)
        order = sorted(range(len(docs)), key=lambda i: scores[i], reverse=True)[:k]
        out = []
        for i in order:
            txt = docs[i].strip()
            if not txt: continue
            out.append({"page": pnos[i], "snippet": txt[:per_len], "score": float(scores[i])})
        return out

    # 2) í‚¤ì›Œë“œ ì ìˆ˜
    weights = {w: 2.0 for w in qtok}
    scored = []
    for i, txt in enumerate(docs):
        toks = _tok(txt)
        if not toks: continue
        score = sum(weights.get(t, 0.0) for t in toks)
        scored.append((i, score))
    scored.sort(key=lambda x: x[1], reverse=True)
    out = []
    for i, sc in scored[:k]:
        t = docs[i].strip()
        if not t: continue
        out.append({"page": pnos[i], "snippet": t[:per_len], "score": float(sc)})
    return out


# ============================== í…ìŠ¤íŠ¸ ì •ë¦¬ ==============================
def _format_paragraphs(text: str, bullets: bool = False) -> str:
    """
    ë¬¸ë‹¨/ë¬¸ì¥ ì¤„ë°”ê¿ˆì„ ê°•ì œí•˜ê³ , ê¸°ì¡´ì— ë¶™ì–´ì˜¨ ë¶ˆë¦¿(â—¦ â€¢ - Â· *) ë“±ì„ ì œê±°í•œ ë’¤
    ì˜µì…˜ì— ë”°ë¼ ì•ì— 'â—¦ 'ë§Œ ë¶™ì—¬ ê¹”ë”í•˜ê²Œ ì¶œë ¥í•œë‹¤.
    """
    if not text:
        return ""

    # 1) <br> ê°™ì€ íƒœê·¸ê°€ ì„ì—¬ ì˜¤ë©´ ê°œí–‰ìœ¼ë¡œ ì¹˜í™˜
    t = re.sub(r"<br\s*/?>", "\n", text, flags=re.I)

    # 2) ìš°ì„  ëª…ì‹œì  ê°œí–‰ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°¬. (ì—†ìœ¼ë©´ ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€)
    raw_parts = [p for p in re.split(r"\n+", t) if p.strip()]
    if not raw_parts:
        raw_parts = re.split(r"(?<=[\.!?])\s+(?=[^\s])", t.strip())

    out: List[str] = []
    for p in raw_parts:
        s = p.strip()
        if not s:
            continue
        # 3) ì•ì— ì´ë¯¸ ë¶™ì–´ìˆëŠ” ë¶ˆë¦¿ë¥˜ ì œê±° (â—¦ â€¢ Â· * - â€“ ë“±)
        s = re.sub(r"^[\u2022â€¢â—¦\-\â€“\Â·\*]+\s*", "", s).strip()

        # 4) ë¶ˆë¦¿ ì˜µì…˜ì— ë”°ë¼ ì ‘ë‘ì–´ ë¶€ì°©
        out.append(("â—¦ " + s) if bullets else s)

    # 5) ì¤„ë°”ê¿ˆ ìœ ì§€ (pre-wrap ìŠ¤íƒ€ì¼ê³¼ í•¨ê»˜ ì“°ë©´ ì›í•˜ëŠ” ëª¨ì–‘)
    return "\n".join(out)

def _cleanup_text_for_grounds(text: str) -> str:
    if not text: 
        return ""
    cleaned: List[str] = []
    for raw in text.split("\n"):
        ln = raw.strip()
        if not ln:
            continue
        # --- ê±¸ëŸ¬ë‚¼ íŒ¨í„´ë“¤ ---
        if re.search(r"\|.+\|", ln): continue                     # í‘œ í˜•íƒœ ë¼ì¸
        if re.match(r"^\s*[-:|]+\s*$", ln): continue              # êµ¬ë¶„ì„ 
        if re.match(r"^\s*(?:<\s*í‘œ|<\s*ê·¸ë¦¼|í‘œ\s*\d|ê·¸ë¦¼\s*\d)", ln): continue  # í‘œ/ê·¸ë¦¼ ìº¡ì…˜
        if re.match(r"^\s*ì œ?\s*\d+\s*ì¥", ln): continue          # ì¥ ì œëª©
        if re.match(r"^\d{1,2}\s*$", ln): continue                # ìˆ«ì ë‹¨ë…
        if ln.lower() in {"ëª©ì°¨", "í‘œ ëª©ì°¨", "ê·¸ë¦¼ ëª©ì°¨", "contents", "table of contents"}: continue
        if re.match(r"^[ivxlcdm]+$", ln.lower()): continue        # ë¡œë§ˆ ìˆ«ì
        if "ì°¨íŠ¸" in ln or "ê·¸ë¦¼" in ln or "í‘œ " in ln: continue  # ëª©ì°¨ì„± ë¼ì¸
        if "ëª©ì°¨" in ln: continue
        # --- ì‹¤ì œ ë‚´ìš©ë§Œ ë‚¨ê¸°ê¸° ---
        cleaned.append(ln)
    return "\n".join(cleaned)


def _format_answer(answer: str) -> str:
    """LLM ë‹µë³€ì„ 1. / â—¦ í˜•ì‹ìœ¼ë¡œ ë¬¸ë‹¨ ë‚˜ëˆ”"""
    if not answer: return ""
    lines = [ln.strip() for ln in answer.split("\n") if ln.strip()]
    formatted, current = [], []
    for ln in lines:
        if re.match(r"^\d+\.", ln):
            if current: formatted.append("\n".join(current))
            current = [ln]  # ìƒˆ í•­ëª© ì‹œì‘
        else:
            current.append(f"â—¦ {ln}" if not ln.startswith("â—¦") else ln)
    if current: formatted.append("\n".join(current))
    return "\n\n".join(formatted)  # í•­ëª© ì‚¬ì´ ë¹ˆ ì¤„

# ğŸ”§ ì¶”ê°€: ê·¼ê±° ìƒìœ„ 3ê°œë§Œ ì„ íƒ
def _select_top_grounds(text: str, max_n: int = 3) -> str:
    if not text: return ""
    sents = re.split(r"(?<=[.!?])\s+", text.strip())
    uniq = []
    for s in sents:
        s = s.strip()
        if not s or s in uniq: continue
        uniq.append(s)
        if len(uniq) >= max_n: break
    return "\n".join([f"â—¦ {u}" for u in uniq])


# ============================== í—¬í¼ ==============================
def _find_table_full(chunks: Dict[str, Any], label: str) -> Optional[Dict[str, Any]]:
    """ë¼ë²¨(ì˜ˆ: 2-1)ë¡œ í‘œ ì°¾ê¸°"""
    for t in chunks.get("tables", []):
        if str(t.get("label", "")).strip() == str(label).strip():
            return t
    return None


def _find_figure_full(chunks: Dict[str, Any], label: str) -> Optional[Dict[str, Any]]:
    """ë¼ë²¨(ì˜ˆ: 3-2)ë¡œ ê·¸ë¦¼ ì°¾ê¸°"""
    for f in chunks.get("figures", []):
        if str(f.get("label", "")).strip() == str(label).strip():
            return f
    return None


def _neighbor_text(chunks: Dict[str, Any], page: int) -> str:
    """í•´ë‹¹ í˜ì´ì§€ Â±1 ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê²°í•©"""
    texts = [x for x in chunks.get("texts", []) if abs(x.get("page", 0) - page) <= 1]
    return "\n".join([(t.get("text") or "") for t in texts])[:2500]


def render_markdown_table(md_table: str):
    """
    ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ìì—´ì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„ Streamlit í‘œë¡œ ì¶œë ¥
    """
    try:
        lines = [ln.strip() for ln in md_table.splitlines() if "|" in ln]
        if not lines:
            st.markdown(md_table)  # í‘œê°€ ì•„ë‹ˆë©´ ê·¸ëƒ¥ ë§ˆí¬ë‹¤ìš´ ì¶œë ¥
            return

        # ì²« ì¤„ = í—¤ë”, ë‘ ë²ˆì§¸ ì¤„ = êµ¬ë¶„ì„ , ë‚˜ë¨¸ì§€ = ë°ì´í„°
        header = [h.strip() for h in lines[0].split("|") if h.strip()]
        rows = []
        for ln in lines[2:]:
            parts = [p.strip() for p in ln.split("|")]
            if any(parts):
                row = [p for p in parts if p != ""]
                if row:
                    rows.append(row)

        if not rows:
            st.markdown(md_table)
            return

        df = pd.DataFrame(rows, columns=header)
        st.table(df)  # âœ… ì˜ˆìœ Streamlit í‘œ ì¶œë ¥
    except Exception:
        st.markdown(md_table)


# ================================== í‘œ ë³€í™˜ ë³´ì¡°í•¨ìˆ˜ ==================================
# ì‚¬ìš©ìê°€ "í‘œ"ë¼ê³  ìš”ì²­í–ˆì„ ë•Œ(_qa_pipeline/_qa_pipeline_tables_only ë‚´ë¶€)ë§Œ í˜¸ì¶œë©ë‹ˆë‹¤.
# - ì…ë ¥ í…ìŠ¤íŠ¸(ctx)ì— ìˆ«ì/ë‹¨ìœ„ê°€ ì¶©ë¶„íˆ í¬í•¨ë˜ë©´ LLMì—ê²Œ "ë§ˆí¬ë‹¤ìš´ í‘œ"ë§Œ ìƒì„±í•˜ë„ë¡ ìš”ì²­
# - í‘œë¡œ ë§Œë“¤ê¸° ì• ë§¤í•˜ë©´ Noneì„ ë°˜í™˜í•´ì„œ ìƒìœ„ ë¡œì§ì´ ì•„ë¬´ ê²ƒë„ ì¶”ê°€í•˜ì§€ ì•Šë„ë¡ ì„¤ê³„
from typing import Optional

def make_table_from_text(text: str, max_chars: int = 1800) -> Optional[str]:
    """
    ë³¸ë¬¸ í…ìŠ¤íŠ¸ì—ì„œ ìˆ˜ì¹˜ ë‚˜ì—´ì„ ê°ì§€í•˜ë©´, í‘œ(ë§ˆí¬ë‹¤ìš´)ë¡œ ë³€í™˜í•´ ì£¼ëŠ” ë³´ì¡° í•¨ìˆ˜.
    - ë°˜í™˜: ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ìì—´ ë˜ëŠ” None
    - ì•ˆì „ì¥ì¹˜:
        * ìˆ«ì/ë‹¨ìœ„ íŒ¨í„´ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ None
        * ë„ˆë¬´ ê¸´ ì…ë ¥ì€ ì˜ë¼ì„œ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©
        * LLM ê²°ê³¼ê°€ í‘œ í˜•íƒœê°€ ì•„ë‹ˆë©´ None
        * ê³¼ë„í•˜ê²Œ ê¸´ í‘œëŠ” ì¤„ ìˆ˜ë¥¼ ì œí•œ
    """
    if not text:
        return None

    # 1) "í‘œë¡œ ë§Œë“¤ ê°€ì¹˜ê°€ ìˆëŠ”ê°€?" ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±
    #    - ìˆ«ì/ë‹¨ìœ„ íŒ¨í„´ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ í‘œ ì‹œë„ ìì²´ë¥¼ í•˜ì§€ ì•ŠìŒ(ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ ë°©ì§€)
    digit_count = sum(1 for ch in text if ch.isdigit())
    numeric_patterns = [
        r"\d{4}\.\d{1,2}",                   # 2021.10 ê°™ì€ ì—°-ì›”
        r"\d+(?:,\d{3})+(?:\.\d+)?",         # 12,345.67 ê°™ì€ ì²œë‹¨ìœ„+ì†Œìˆ˜
        r"\d+\.\d+",                         # 3.14 ê°™ì€ ì†Œìˆ˜
        r"\d+%",                             # í¼ì„¼íŠ¸
        r"\d+\s*(?:ì›|KRW|ë§Œì›|ì–µì›|ì¡°ì›)",     # ê¸ˆì•¡/í†µí™”
        r"kWh|kW|MW|GWh|tCO2e|ppm|ppb",      # ë‹¨ìœ„(ì—ë„ˆì§€/í™˜ê²½)
    ]
    looks_numeric = any(re.search(p, text) for p in numeric_patterns)
    if not (looks_numeric or digit_count >= 10):
        return None

    # 2) ê³¼ë„í•˜ê²Œ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì„œ ì‚¬ìš© (í† í° ë‚­ë¹„ ë°©ì§€)
    src = (text or "")[:max_chars]

    # 3) LLMì— "í‘œë§Œ" ìƒì„±í•˜ë„ë¡ ëª…í™•íˆ ì§€ì‹œ (ì„¤ëª…/ì½”ë“œíœìŠ¤ ê¸ˆì§€)
    prompt = (
        "ì•„ë˜ í…ìŠ¤íŠ¸ì˜ ìˆ˜ì¹˜/ë‹¨ìœ„ë¥¼ í‘œ(ë§ˆí¬ë‹¤ìš´)ë¡œë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì¤˜.\n"
        "- ë§ˆí¬ë‹¤ìš´ í‘œë§Œ ì¶œë ¥ (ì„¤ëª… ë¬¸ì¥/ì½”ë“œë¸”ë¡ ê¸ˆì§€).\n"
        "- ì²« ì—´ì€ 'í•­ëª©' ë˜ëŠ” 'êµ¬ë¶„'.\n"
        "- ê°’ì—ëŠ” ë‹¨ìœ„(%, ì›, kWh ë“±)ë¥¼ í¬í•¨.\n"
        "- ì—´ì€ ìµœëŒ€ 4ê°œ ì´ë‚´ë¡œ ìš”ì•½.\n"
        "- í–‰/ì—´ ì œëª©ì€ ê°„ê²°í•˜ê²Œ.\n"
        "- ë¶ˆí•„ìš”í•œ ì£¼ì„/ì¶œì²˜/ë¬¸ì¥ ì¶”ê°€ ê¸ˆì§€.\n\n"
        f"[ì›ë¬¸ í…ìŠ¤íŠ¸]\n{src}"
    )

    try:
        # NOTE: llm.explain_tablesë¥¼ ì¨ë„ ë˜ì§€ë§Œ, í˜„ì¬ íŒŒì¼ì—ì„œ ì´ë¯¸ ì“°ëŠ” answer_with_contextë¡œ í†µì¼
        md = answer_with_context("í…ìŠ¤íŠ¸ë¥¼ í‘œë¡œ ì •ë¦¬", prompt, page_label=None).strip()
    except Exception:
        return None

    # 4) ëª¨ë¸ì´ ê°€ë” ```ë¡œ ê°ì‹¸ëŠ” ê²½ìš° ì œê±°
    md = re.sub(r"^```.*?\n", "", md)
    md = re.sub(r"\n```$", "", md)

    # 5) ìµœì†Œí•œì˜ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•íƒœ ê²€ì‚¬
    #    - íŒŒì´í”„(|)ê°€ ì—†ìœ¼ë©´ í‘œê°€ ì•„ë‹˜
    if "|" not in md:
        return None

    # 6) í‘œê°€ ë„ˆë¬´ ê¸¸ë©´ ì»· (UI ë³´í˜¸)
    lines = [ln.rstrip() for ln in md.splitlines() if ln.strip()]
    if len(lines) > 50:
        lines = lines[:50] + ["| ... | ... |", "| (ì¤‘ëµ) | (ì¤‘ëµ) |"]

    return "\n".join(lines)

# ============================== ìŠ¤íƒ€ì¼ ==============================
def _inject_css():
    """ê³µí†µ/ë¡œì»¬ CSS ì£¼ì…"""
    base = get_css()
    local = f"""
    <style>
      /* ì‚¬ìš©ì ì§ˆë¬¸ ë§í’ì„ (ìš°ì¸¡) */
      .hp-msg.user {{ display:flex; justify-content:flex-end; margin: 6px 0; }}
      .hp-msg.user .bubble {{
        background:{ACCENT}; color:#fff; padding:12px 16px; border-radius:16px;
        max-width:72%; font-size:16px; white-space:pre-wrap; box-shadow:0 1px 2px rgba(0,0,0,.06);
      }}

      /* ë‹µë³€ ì¹´ë“œ */
      .hp-card {{ background:#fff; border:1px solid #e9ecef; border-radius:16px;
                 padding:16px 18px; margin:12px 0; box-shadow:0 2px 6px rgba(0,0,0,.04); }}
      .hp-card__title {{ font-weight:900; font-size:25px; margin-bottom:10px; }}
      .hp-card__text {{ white-space:pre-wrap; line-height:1.7; font-size:16px; }}

      /* ì›ë¬¸ ìš”ì•½ ë°•ìŠ¤ */
      .hp-answer-box1 {{
        background:#ffffff;
        padding:12px 14px; font-size:16px; line-height:1.7; white-space:pre-wrap;
      }}

      /* íšŒìƒ‰ ìš”ì•½ ë°•ìŠ¤ */
      .hp-answer-box {{
        background:#f5f6f8; border:1px solid #e6e8eb; border-radius:12px;
        padding:14px 16px; font-size:16px; line-height:1.7; white-space:pre-wrap;
      }}

      /* ê·¸ë¦¼/í‘œ ì œëª© */
      .hp-figtitle {{ text-align:center; font-weight:800; font-size:20px; margin:6px 0 8px 0; }}

      /* ğŸ”§ ì§ˆë¬¸-ë‹µë³€ ì‚¬ì´ ì—¬ë°±/í° ë°•ìŠ¤ ì œê±° */
      .hp-msg.user + div:has(.hp-card) {{ margin-top: 0 !important; }}
      .hp-card:first-child {{ margin-top: 6px; }}

      /* âœ… ì±„íŒ… ì…ë ¥ì°½ì„ í™”ë©´ í•˜ë‹¨ì— ê³ ì • (í‘¸í„° ìŠ¤íƒ€ì¼) */
      section[data-testid="stChatInput"] {{
          position: fixed;
          bottom: 0;
          left: 320px;  /* ì‚¬ì´ë“œë°” í­ ê³ ë ¤ */
          right: 0;
          background: white;
          padding: 10px 16px;
          border-top: 1px solid #ddd;
          z-index: 100;
      }}
    </style>
    """
    st.markdown(f"<style>{base}</style>", unsafe_allow_html=True)
    st.markdown(local, unsafe_allow_html=True)


# ============================== ì—”íŠ¸ë¦¬ ==============================
def run():
    route = st.session_state.get("route", "landing")
    if route == "landing":
        landing_page()
    elif route == "loading":
        loading_page()
    else:
        analysis_page()
