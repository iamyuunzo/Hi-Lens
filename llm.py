# llm.py â€” í‘œ/ê·¸ë¦¼ ì»¨í…ìŠ¤íŠ¸ ë³´ê°• + (ì‹ ê·œ) ê·¸ë¦¼ ì´ë¯¸ì§€ ì§ì ‘ ìš”ì•½ ì§€ì› (ì „ì²´ ì½”ë“œ)

from __future__ import annotations
import os
import io
from typing import Optional, List, Dict, Any, Union

import streamlit as st
import google.generativeai as genai

try:
    from PIL import Image as PILImage
except Exception:
    PILImage = None

__all__ = [
    "get_provider_name",
    "SUMMARIZER_DEFAULT_SYSTEM",
    "llm_chat",
    "answer_with_context",
    "explain_tables",
    "explain_figure_image",
]

_DIAG_DONE = False


def _get_api_key() -> Optional[str]:
    global _DIAG_DONE
    key, source = None, None
    try:
        for name in ("GEMINI_API_KEY", "GOOGLE_API_KEY", "GOOGLE_GENERATIVEAI_API_KEY"):
            if name in st.secrets and st.secrets[name]:
                key = st.secrets[name]; source = f"st.secrets[{name}]"; break
    except Exception:
        pass
    if not key:
        for name in ("GEMINI_API_KEY", "GOOGLE_API_KEY", "GOOGLE_GENERATIVEAI_API_KEY"):
            v = os.getenv(name)
            if v: key, source = v, f"os.getenv('{name}')"; break
    if not _DIAG_DONE:
        st.toast(("âœ… í‚¤ ê°ì§€ " + source) if key else "âš ï¸ í‚¤ ë¯¸ê°ì§€", icon="âœ…" if key else "âš ï¸")
        _DIAG_DONE = True
    return key


def _get_model(model_name: str = "gemini-1.5-flash", system_instruction: Optional[str] = None):
    api_key = _get_api_key()
    if not api_key:
        st.error("âŒ GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    genai.configure(api_key=api_key)
    if system_instruction:
        return genai.GenerativeModel(model_name, system_instruction=system_instruction)
    return genai.GenerativeModel(model_name)


def get_provider_name() -> str:
    return "GEMINI"


SUMMARIZER_DEFAULT_SYSTEM = (
    "ë‹¹ì‹ ì€ ì •ì±…/ë³´ê³ ì„œ ì „ë¬¸ ìš”ì•½ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œ ë°– ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ê³  "
    "ëª…í™•í•œ í•œêµ­ì–´ë¡œ í•µì‹¬ì„ ì •ë¦¬í•˜ì„¸ìš”."
)


def llm_chat(system_prompt: str, user_prompt: str, model_name: str = "gemini-1.5-flash") -> str:
    model = _get_model(model_name, system_instruction=system_prompt)
    try:
        resp = model.generate_content(user_prompt)
        return getattr(resp, "text", "").strip() or "âš ï¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âš ï¸ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}"


# -----------------------------------------------------------------------------  
# ğŸ”§ ìˆ˜ì •: answer_with_context â†’ ë‹µë³€ í˜•ì‹ ê°•í™”  
# -----------------------------------------------------------------------------
def answer_with_context(query: str, context: str, page_label: Optional[str] = None) -> str:
    model = _get_model()
    page_note = f"(ê·¼ê±° p.{page_label})" if page_label else ""
    prompt = f"""
ì•„ë˜ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. {page_note}

[ë‹µë³€ ê·œì¹™]
- ë‹µë³€ì€ 3~4ë¬¸ì¥ ì •ë„ì˜ ë‹¨ë½í˜• ìš”ì•½ìœ¼ë¡œ ì‘ì„±
- ë²ˆí˜¸ ë§¤ê¸°ê¸°, ë¶ˆë¦¿ ì‚¬ìš© ê¸ˆì§€
- ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ë§¥ì— ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”
- ë¶ˆí•„ìš”í•œ <br>, HTML, í‘œëŠ” ê¸ˆì§€

[ë¬¸ë§¥]
{context}

[ì§ˆë¬¸]
{query}
""".strip()
    try:
        resp = model.generate_content(prompt)
        return getattr(resp, "text", "").strip() or "âš ï¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âš ï¸ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}"


def explain_tables(query: str, tables_ctxs: List[Dict[str, Any]]) -> str:
    model = _get_model()
    parts = []
    for t in tables_ctxs:
        title = (t.get("title") or "").strip()
        pno   = t.get("page_label", "?")
        prev  = (t.get("preview_md") or "").strip()
        nb    = (t.get("neighbor_text") or "").strip()
        sparse = len(prev) < 40 or prev.count("|") <= 2
        ctx_block = f"(p.{pno}) {title}\n"
        if sparse and nb:
            ctx_block += f"[í‘œ ë¯¸ë¦¬ë³´ê¸° ì¶”ì •ì´ ë¹ˆì•½í•˜ì—¬ ë³¸ë¬¸ ë³´ê°•]\n{nb}\n"
        ctx_block += (prev if prev else "")
        parts.append(ctx_block)

    ctx = ("\n\n---\n\n".join(parts))[:7800] if parts else "í‘œ ë¯¸ê²€ì¶œ"
    prompt = f"""
ë‹¹ì‹ ì€ í‘œ/ê·¸ë¦¼ì„ ì„¤ëª…í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.
- [ì»¨í…ìŠ¤íŠ¸] ë²”ìœ„ ë‚´ì—ì„œë§Œ ë‹µí•˜ì„¸ìš”.
- ë‹µë³€ì€ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ê°„ê²°íˆ.
- ì¶”ì„¸Â·ë¹„êµÂ·í•µì‹¬ í¬ì¸íŠ¸ë§Œ ì„¤ëª…í•˜ì„¸ìš”.

[ì§ˆë¬¸]
{query}

[ì»¨í…ìŠ¤íŠ¸]
{ctx}
""".strip()
    try:
        resp = model.generate_content(prompt)
        return getattr(resp, "text", "").strip() or "âš ï¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âš ï¸ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}"


def _to_pil(image: Union[bytes, "PILImage.Image", Any]) -> Optional["PILImage.Image"]:
    if PILImage is None:
        return None
    try:
        if isinstance(image, PILImage.Image): return image
        if isinstance(image, (bytes, bytearray)): return PILImage.open(io.BytesIO(image))
        try:
            import numpy as np
            if isinstance(image, np.ndarray):
                if image.ndim == 2: return PILImage.fromarray(image)
                if image.ndim == 3: return PILImage.fromarray(image.astype("uint8"))
        except Exception:
            pass
    except Exception:
        return None
    return None


def explain_figure_image(query: str, image: Union[bytes, "PILImage.Image", Any], neighbor_text: str = "") -> str:
    pil = _to_pil(image)
    if pil is None:
        return answer_with_context(
            query,
            f"[ì´ë¯¸ì§€ ë¯¸ì „ë‹¬/ë¡œë”©ì‹¤íŒ¨] ì•„ë˜ ë³¸ë¬¸ë§Œìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n{(neighbor_text or '')[:1800]}",
            page_label=None,
        )
    system = (
        "ë‹¹ì‹ ì€ ë°ì´í„° ì‹œê°í™”ë¥¼ ì •í™•íˆ ì½ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
        "ê·¸ë˜í”„/ì°¨íŠ¸ì˜ ì œëª©/ì¶•/ë²”ë¡€/ë‹¨ìœ„ë¥¼ í•´ì„í•˜ê³ , í•µì‹¬ ì¶”ì„¸Â·ë³€í™”Â·ë¹„êµë§Œ ê°„ê²°íˆ ì„¤ëª…í•˜ì„¸ìš”. "
        "ìˆ˜ì¹˜ëŠ” ì¤‘ìš”í•œ ê²ƒë§Œ, ê³¼ë„í•œ ë‚˜ì—´ ê¸ˆì§€."
    )
    parts = [
        {"text": f"[ì§ˆë¬¸]\n{query}\n\n[ì°¸ê³  ë³¸ë¬¸]\n{(neighbor_text or '')[:1500]}"},
        pil,
    ]
    try:
        model = _get_model("gemini-1.5-flash", system_instruction=system)
        resp = model.generate_content(parts)
        txt = getattr(resp, "text", "").strip()
        return txt or "âš ï¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    except Exception:
        return answer_with_context(
            query,
            f"[ì´ë¯¸ì§€ ìš”ì•½ ì‹¤íŒ¨: ë©€í‹°ëª¨ë‹¬ í˜¸ì¶œ ì˜ˆì™¸] ì•„ë˜ ë³¸ë¬¸ë§Œìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n{(neighbor_text or '')[:1800]}",
            page_label=None,
        )
