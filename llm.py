# llm.py (Gemini ì „ìš©) - ë°°í¬ í˜•ì‹
# -*- coding: utf-8 -*-
# ==========================================
# LLM ê´€ë ¨ ê¸°ëŠ¥ ëª¨ë“ˆ
# - Gemini API ì´ˆê¸°í™”
# - ì§ˆë¬¸ ì‘ë‹µ(answer_with_context)
# - Provider ì´ë¦„ ë°˜í™˜(get_provider_name)
# - í…Œì´ë¸” ì„¤ëª…(explain_tables)
# ==========================================

import os
import streamlit as st
import google.generativeai as genai


# ==============================
# ğŸ”‘ GEMINI API KEY ë¶ˆëŸ¬ì˜¤ê¸°
# ==============================
# 1. Streamlit Cloudì—ì„œëŠ” st.secrets ì‚¬ìš©
# 2. ë¡œì»¬ ì‹¤í–‰ ì‹œ os.getenv(.env, í™˜ê²½ë³€ìˆ˜)
API_KEY = st.secrets.get("GEMINI_API_KEY", None) or os.getenv("GEMINI_API_KEY")

if not API_KEY:
    raise RuntimeError(
        "âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
        "ğŸ‘‰ í•´ê²° ë°©ë²•:\n"
        "   1) ë¡œì»¬ ì‹¤í–‰ ì‹œ: .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— GEMINI_API_KEY ë“±ë¡\n"
        "   2) Streamlit Cloud ë°°í¬ ì‹œ: Settings â†’ Secretsì—\n"
        '      GEMINI_API_KEY = "ë°œê¸‰ë°›ì€_ì‹¤ì œ_API_KEY"\n'
    )

# âœ… Google Gemini API ì´ˆê¸°í™”
genai.configure(api_key=API_KEY)


# ==============================
# Provider ì´ë¦„ ë°˜í™˜
# ==============================
def get_provider_name() -> str:
    return "GEMINI"


# ==============================
# ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ í•¨ìˆ˜
# ==============================
def answer_with_context(query: str, context: str) -> str:
    """
    query: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸
    context: ë¬¸ì„œ/ë°ì´í„°ì—ì„œ ë½‘ì•„ì˜¨ ê´€ë ¨ ë¬¸ë§¥

    return: Gemini ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    model = genai.GenerativeModel("gemini-1.5-flash")

    # Geminiì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
    prompt = f"""
    ì•„ë˜ ë¬¸ë§¥(context)ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸(query)ì— ë‹µë³€í•˜ì„¸ìš”.

    [Context]
    {context}

    [Question]
    {query}
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}"


# ==============================
# í…Œì´ë¸” ì„¤ëª… í•¨ìˆ˜
# ==============================
def explain_tables(table_text: str) -> str:
    """
    table_text: PDF ë“±ì—ì„œ ì¶”ì¶œëœ í…Œì´ë¸” ë¬¸ìì—´

    return: í…Œì´ë¸” ì˜ë¯¸ë¥¼ ì‚¬ëŒì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…
    """
    model = genai.GenerativeModel("gemini-1.5-flash")

    prompt = f"""
    ì•„ë˜ì˜ í‘œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í‘œì˜ ì˜ë¯¸ì™€ ì£¼ìš” íŠ¹ì§•ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

    [Table]
    {table_text}
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}"



# # llm.py (Gemini ì „ìš©) - env í˜•ì‹
# # -*- coding: utf-8 -*-
# """
# LLM (Gemini ì „ìš©)
# - í‘œ ìš”ì•½ / ë³¸ë¬¸ ë°œì·Œ ìš”ì•½ / ì¼ë°˜ chat í—¬í¼
# - í™˜ê° ë°©ì§€: ë¯¸ë¦¬ë³´ê¸°/ë°œì·Œ + í˜ì´ì§€ë²ˆí˜¸ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©
# """

# from __future__ import annotations
# import os
# from typing import Dict, List
# from dotenv import load_dotenv
# import google.generativeai as genai

# # .env ë¡œë“œ
# load_dotenv(override=True)

# GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
# if not GEMINI_API_KEY:
#     raise RuntimeError("âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Google AI Studioì—ì„œ ë°œê¸‰ í›„ .envì— GEMINI_API_KEY=... ë¡œ ë„£ì–´ì£¼ì„¸ìš”.")

# # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# genai.configure(api_key=GEMINI_API_KEY)

# # ëª¨ë¸ì€ ê²½ëŸ‰Â·ì†ë„ ìš°ì„ . í•„ìš”í•˜ë©´ proë¡œ êµì²´ ê°€ëŠ¥.
# DEFAULT_MODEL = "gemini-1.5-flash-latest"

# def get_provider_name() -> str:
#     return "GEMINI"

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # (A) í‘œ ìš”ì•½
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EXPLAIN_TABLES_PROMPT = """
# ë‹¹ì‹ ì€ 'ì •ì±… PDF í‘œ ë¶„ì„ ë³´ì¡°ì›'ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ê·œì¹™ì„ ì§€í‚¤ì„¸ìš”.

# [ê·œì¹™]
# 1) ì˜¤ì§ 'ì œê³µëœ í‘œ ë¯¸ë¦¬ë³´ê¸°(Markdown)'ì™€ 'í˜ì´ì§€ ë²ˆí˜¸'ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
# 2) í‘œì— ì—†ëŠ” ìˆ˜ì¹˜/í•­ëª©/í•´ì„ì„ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤(ì¶”ì¸¡ ê¸ˆì§€).
# 3) ì¶œë ¥ì€ ìµœëŒ€ 5ì¤„ bullet. ê° bulletì€ 'ë¬´ìŠ¨ í‘œì¸ì§€'ì™€ 'í•µì‹¬ ë³€í™”/íŠ¹ì§•'ì„ ì§§ê²Œ ê¸°ìˆ í•©ë‹ˆë‹¤.
# 4) ê°€ëŠ¥í•˜ë©´ bullet ëì— (p.ë²ˆí˜¸)ë¡œ ê·¼ê±° í˜ì´ì§€ë¥¼ í‘œê¸°í•©ë‹ˆë‹¤.
# """.strip()

# def explain_tables(user_query: str, table_contexts: List[Dict]) -> str:
#     """
#     ì—¬ëŸ¬ í‘œ ë¯¸ë¦¬ë³´ê¸°(Markdown)ì™€ í˜ì´ì§€ ë¼ë²¨ì„ ë°›ì•„ bullet ìš”ì•½ì„ ìƒì„±.
#     - table_contexts: [{"preview_md": str, "page_label": int, "title": str}, ...]
#     """
#     parts = []
#     for i, t in enumerate(table_contexts, 1):
#         title = (t.get("title") or "").strip()
#         head = f"[í‘œ{i}] p.{t.get('page_label','?')}" + (f" Â· {title}" if title else "")
#         body = (t.get("preview_md") or "").strip()[:3000]
#         if not body:
#             continue
#         parts.append(head + "\n" + body)
#     ctx = "\n\n".join(parts) if parts else "(í‘œ ë¯¸ë¦¬ë³´ê¸°ê°€ ë¹„ì–´ìˆìŒ)"

#     try:
#         model = genai.GenerativeModel(DEFAULT_MODEL)
#         res = model.generate_content(
#             f"{EXPLAIN_TABLES_PROMPT}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n\n[í‘œ ë¯¸ë¦¬ë³´ê¸°]\n{ctx}"
#         )
#         out = (res.text or "").strip()
#         lines = [ln for ln in out.splitlines() if ln.strip()]
#         return "\n".join(lines[:8]) if lines else "í‘œ ë¯¸ë¦¬ë³´ê¸°ê°€ ë¶€ì¡±í•˜ì—¬ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
#     except Exception as e:
#         return f"âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}"

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # (B) ë³¸ë¬¸ ë°œì·Œ ìš”ì•½
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ANSWER_WITH_CONTEXT_PROMPT = """
# ë‹¹ì‹ ì€ 'ì›ë¬¸ ê·¼ê±° ìš”ì•½ì'ì…ë‹ˆë‹¤. ê·œì¹™:
# - 'ì œê³µëœ ë³¸ë¬¸ ë°œì·Œ'ì—ì„œë§Œ ë‹µí•˜ì„¸ìš”(ì¶”ì¸¡ ê¸ˆì§€).
# - 3~5ì¤„ bulletë¡œ ê°„ê²° ìš”ì•½, ë§ˆì§€ë§‰ ì¤„ì— (p.ë²ˆí˜¸)ë¥¼ ë¶™ì´ì„¸ìš”.
# """.strip()

# def answer_with_context(user_query: str, context: str, page_label: str|int = "?") -> str:
#     """ê°„ë‹¨í•œ ë°œì·Œ ìš”ì•½(ëŒ€í™” íƒ­ ìƒë‹¨ Â· í´ë°±ì—ë„ ì‚¬ìš©)."""
#     if not context.strip():
#         return "ê·¼ê±° ë°œì·Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
#     try:
#         model = genai.GenerativeModel(DEFAULT_MODEL)
#         res = model.generate_content(
#             f"{ANSWER_WITH_CONTEXT_PROMPT}\n\nì§ˆë¬¸: {user_query}\n\n[ë³¸ë¬¸ ë°œì·Œ]\n{context}\n(p.{page_label})"
#         )
#         return (res.text or "").strip()
#     except Exception as e:
#         return f"âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}"

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # (C) ì¼ë°˜ chat í—¬í¼ (ê³„ì¸µ ìš”ì•½ ë“±ì—ì„œ ì¬ì‚¬ìš©)
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # ìš”ì•½ ì „ìš© system í”„ë¡¬í”„íŠ¸: ë©”íƒ€ë°ì´í„°(ì œëª©/ì €ì/ë°œê°„ì •ë³´/ì´ˆë¡) ë°°ì œ
# SUMMARIZER_DEFAULT_SYSTEM = """
# ë‹¹ì‹ ì€ ì •ì±… ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.
# - 'ë¬¸ì„œ ë©”íƒ€ë°ì´í„°(ì œëª©/ì €ì/ë°œí–‰ê¸°ê´€/ì´ˆë¡/í‘œì§€/ë°œê°„ì •ë³´)'ëŠ” ìš”ì•½ ëŒ€ìƒì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
# - ë³¸ë¬¸ì— ë‚˜íƒ€ë‚œ 'ì •ì±… ë³€í™”/ì‹œì¥ ë™í–¥/í•µì‹¬ ìˆ˜ì¹˜/ì‹œì‚¬ì 'ë§Œ ìš”ì•½í•©ë‹ˆë‹¤.
# - ë¬¸ì„œ ë°”ê¹¥ ì§€ì‹/ì¶”ì¸¡ ê¸ˆì§€.
# """.strip()

# def llm_chat(system: str, user: str) -> str:
#     """
#     ì„ì˜ì˜ system+user í”„ë¡¬í”„íŠ¸ë¥¼ í˜¸ì¶œí•˜ëŠ” ê°„ë‹¨í•œ ë˜í¼.
#     - summarizer.py ë“±ì—ì„œ ê³µìš©ìœ¼ë¡œ ì‚¬ìš©.
#     """
#     try:
#         model = genai.GenerativeModel(DEFAULT_MODEL)
#         res = model.generate_content(f"{system}\n\n{user}")
#         return (res.text or "").strip()
#     except Exception as e:
#         return f"âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}"
