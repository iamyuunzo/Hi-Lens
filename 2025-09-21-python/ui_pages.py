# ui_pages.py
# -*- coding: utf-8 -*-
from __future__ import annotations

"""
í™”ë©´ êµ¬ì„± (UI ì „ìš© ìˆ˜ì •)
- ëœë”©: ìƒë‹¨ ìœ ë ¹ ì…ë ¥ë°•ìŠ¤ë§Œ ìˆ¨ê¸°ê³ (ì—…ë¡œë”ëŠ” ìœ ì§€), ì»¨í…Œì´ë„ˆë¥¼ ì¤‘ì•™ ì •ë ¬ + ìƒë‹¨ ê³ ì • ì—¬ë°±(--header-gap)
- ê³µí†µ ì‚¬ì´ë“œë°”: PDF ë‹¨ìœ„ ê¸°ë¡/ë³µì›
- ë¶„ì„: ê¸°ì¡´ ê¸°ëŠ¥/ë¡œì§ ìœ ì§€
"""

import re
import hashlib
import time
import datetime as dt
from typing import Dict, Any, List, Tuple, Optional

import streamlit as st
from styles import get_css

from extract import (
    build_chunks, find_table_by_label, find_figure_by_label,
    crop_table_image, crop_figure_image,
)

# ===== LLM ì–´ëŒ‘í„°(ì—†ìœ¼ë©´ í´ë°±) =====
try:
    from llm import answer_with_context
except Exception:
    def answer_with_context(q: str, ctx: str) -> str:
        lines = [ln.strip() for ln in (ctx or "").splitlines() if ln.strip()]
        return "ìš”ì•½: " + (lines[0][:220] if lines else (ctx or "")[:220])

try:
    from llm import generate_query_tags
except Exception:
    def generate_query_tags(pages: List[Dict], k: int = 12) -> List[str]:
        txt = " ".join(p.get("text","") for p in pages)
        years = sorted(set(re.findall(r"20\\d{2}", txt)))[-3:]
        base = [f"{'~'.join(years)} ì—°ë„ë³„ ì§€í‘œ ë¹„êµí•´ì¤˜"] if years else []
        base += [w+" ì¶”ì´ë¥¼ í‘œë¡œ ë³´ì—¬ì¤˜" for w in ["ê°€êµ¬ì›ìˆ˜","ì—ë„ˆì§€","ë„ì‹œê°€ìŠ¤","ì—°ë£Œë¹„","ì†Œë¹„ì§€ì¶œ"]]
        out, seen = [], set()
        for t in base:
            t = re.sub(r"\\s+", " ", t).strip()
            if t and t not in seen:
                out.append(t); seen.add(t)
            if len(out) >= k: break
        return out

# ================== ì„¸ì…˜/ìŠ¤ë ˆë“œ ìœ í‹¸ ==================
def _pdf_id() -> Optional[str]:
    data = st.session_state.get("pdf_bytes")
    return hashlib.sha1(data).hexdigest()[:12] if data else None

def _threads() -> List[Dict[str,Any]]:
    return st.session_state.setdefault("_threads", [])

def _find_thread(tid: str) -> Optional[Dict[str,Any]]:
    for t in _threads():
        if t["tid"] == tid:
            return t
    return None

def _current_thread() -> Optional[Dict[str,Any]]:
    tid = st.session_state.get("_current_tid")
    return _find_thread(tid) if tid else None

def _ensure_thread():
    if _current_thread():
        return
    pid = _pdf_id()
    name = st.session_state.get("pdf_name") or "ë¬¸ì„œ"
    for t in _threads():
        if t.get("pdf_id") == pid and t.get("pdf_name") == name:
            st.session_state["_current_tid"] = t["tid"]
            return
    tid = f"{pid}-{int(time.time())}"
    t = {
        "tid": tid, "pdf_id": pid, "pdf_name": name,
        "ts": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "messages": [], "pdf_bytes": st.session_state.get("pdf_bytes"),
        "chunks": {},
    }
    _threads().append(t)
    st.session_state["_current_tid"] = tid

def _append_to_thread(item: Dict[str,Any]):
    th = _current_thread()
    if th: th["messages"].append(item)

# ================== ê³µí†µ ì‚¬ì´ë“œë°” ==================
def render_sidebar():
    st.sidebar.markdown("<div class='hp-brand'><span class='dot'></span>Hi-PolicyLens</div>", unsafe_allow_html=True)
    st.sidebar.caption("í˜„ëŒ€í•´ìƒ ë‚´ë¶€ ë¦¬ì„œì¹˜ ë³´ì¡°")

    if st.sidebar.button("ğŸ  í™ˆìœ¼ë¡œ ê°€ê¸°", use_container_width=True):
        st.session_state["route"] = "landing"; st.experimental_rerun()

    st.sidebar.markdown("---")
    st.sidebar.subheader("PDF ë¶„ì„ ê¸°ë¡")

    st.sidebar.markdown("<div class='hp-log-list'>", unsafe_allow_html=True)
    for t in reversed(_threads()):
        label = f"ğŸ“„ {t['pdf_name']} Â· {t['ts']} Â· ì§ˆë¬¸ {len(t['messages'])}ê°œ"
        if st.sidebar.button(label, key=f"hist-{t['tid']}", use_container_width=True):
            st.session_state["_current_tid"] = t["tid"]
            st.session_state["pdf_name"] = t["pdf_name"]
            st.session_state["pdf_bytes"] = t.get("pdf_bytes")
            st.session_state["chunks"] = t.get("chunks", {})
            st.session_state["chat"] = t.get("messages", [])
            st.session_state["route"] = "analysis"
            st.experimental_rerun()
    st.sidebar.markdown("</div>", unsafe_allow_html=True)

    st.sidebar.markdown("---")
    st.sidebar.markdown("<div class='hp-guide'>", unsafe_allow_html=True)
    st.sidebar.subheader("ì‚¬ìš©ì ê°€ì´ë“œ")
    st.sidebar.markdown(
        """
        - ì‚¬ì´ë“œë°” **ê¸°ë¡**ì—ì„œ ì´ì „ ë¶„ì„ PDFë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
        - ì˜¤ë¥¸ìª½ **ëª©ì°¨ íŒ¨ë„**ì—ì„œ ë¹ ë¥¸ íƒœê·¸/í‘œ/ê·¸ë¦¼ì„ íƒìƒ‰í•˜ì„¸ìš”.  
        - í‘œ/ê·¸ë¦¼ì€ **ì›ë³¸ í¬ê²Œ ë³´ê¸°**ë¡œ í™•ëŒ€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """.strip()
    )
    st.sidebar.markdown("</div>", unsafe_allow_html=True)

# ================== ëœë”© ==================
def landing_page():
    st.markdown(f"<style>{get_css()}</style>", unsafe_allow_html=True)
    render_sidebar()

    # ëœë”©: ì±— ì…ë ¥ë§Œ ìˆ¨ê¹€(ì—…ë¡œë”ëŠ” ìœ ì§€), ìŠ¤í¬ë¡¤ ì œê±° + ì¤‘ì•™ ì •ë ¬
    # ğŸ”´ ì—¬ê¸°ì„œ --header-gap(ìƒë‹¨ ê³ ì • ì—¬ë°±)ì„ ì ìš©
    st.markdown("""
    <style>
      [data-testid='stChatInput'] { display:none !important; }
      /* ëœë”© ì»¨í…Œì´ë„ˆë¥¼ 'íˆ´ë°”+ê³ ì • ì—¬ë°±'ë§Œí¼ ì•„ë˜ì—ì„œ ì‹œì‘ + ë‚˜ë¨¸ì§€ ì˜ì—­ ì¤‘ì•™ì •ë ¬ */
      .block-container:has(#hp-landing-sentinel){ padding-top: 0 !important; }
      div[data-testid='stVerticalBlock']:has(> #hp-landing-sentinel){
        height: calc(100vh - var(--top-offset) - var(--header-gap));
        margin-top: var(--header-gap);
        display: flex; flex-direction: column;
        align-items: center; justify-content: center;
      }
      html, body { overflow: hidden !important; }  /* ìŠ¤í¬ë¡¤ ì œê±° */

      /* ì—…ë¡œë”/ë²„íŠ¼ í­ ì •ë¦¬ */
      div[data-testid='stFileUploaderDropzone']{ max-width: 720px; margin: 0 auto; }
      .stButton > button{ max-width: 720px; margin: 0 auto; display:block; }
    </style>
    """, unsafe_allow_html=True)

    # ì„¼í‹°ë„¬: ì´ ì•„ë˜ì˜ ìš”ì†Œë“¤ì„ ì¤‘ì•™ ì •ë ¬ ëŒ€ìƒìœ¼ë¡œ ë¬¶ì–´ì¤Œ
    st.markdown("<div id='hp-landing-sentinel'></div>", unsafe_allow_html=True)

    # ì¤‘ì•™ ì½˜í…ì¸ 
    st.markdown("<h1 style='text-align:center; font-weight:900;'>ğŸ‘‹ Hi-PolicyLens</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center; color:#334155; font-weight:700;'>PDFì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì›ë¬¸ ë°œì·Œí•˜ê³  í‘œ/ê·¸ë¦¼/ë¬¸ë‹¨ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë§ì¶¤í˜• ë„ìš°ë¯¸</p>", unsafe_allow_html=True)

    upl = st.file_uploader("ë¶„ì„í•  PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"], key="landing_upl")
    start = st.button("ğŸ” ë¶„ì„ ì‹œì‘", use_container_width=True)

    if start:
        if not upl:
            st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."); st.stop()
        pdf_bytes = upl.read(); pdf_name = upl.name
        pdf_id = hashlib.sha1(pdf_bytes).hexdigest()[:12]
        tid = f"{pdf_id}-{int(time.time())}"
        _threads().append({
            "tid": tid, "pdf_id": pdf_id, "pdf_name": pdf_name,
            "ts": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "messages": [], "pdf_bytes": pdf_bytes, "chunks": {},
        })
        st.session_state["_current_tid"] = tid
        st.session_state["pdf_bytes"] = pdf_bytes
        st.session_state["pdf_name"]  = pdf_name
        st.session_state["route"] = "loading"
        st.rerun()

# ================== ë¡œë”© ==================
def loading_page():
    st.markdown(f"<style>{get_css()}</style>", unsafe_allow_html=True)
    render_sidebar()

    # ë¡œë”©: ëœë”©ê³¼ ë™ì¼í•˜ê²Œ --header-gap ì ìš©í•´ì„œ ê°„ê²© ë„ì›€ + ì¤‘ì•™ ì •ë ¬ + ìŠ¤í¬ë¡¤ ì—†ìŒ
    st.markdown("""
    <style>
      [data-testid='stChatInput']{ display:none !important; }
      .block-container:has(#hp-loading-sentinel){ padding-top: 0 !important; }
      div[data-testid='stVerticalBlock']:has(> #hp-loading-sentinel){
        height: calc(100vh - var(--top-offset) - var(--header-gap));
        margin-top: var(--header-gap);
        display:flex; align-items:center; justify-content:center;
      }
      html, body { overflow: hidden !important; }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("<div id='hp-loading-sentinel'></div>", unsafe_allow_html=True)
    st.markdown("<div class='hp-loading-card'>", unsafe_allow_html=True)
    st.markdown("<div class='title'>â³ PDFì—ì„œ í‘œ/ê·¸ë¦¼/í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...</div>", unsafe_allow_html=True)

    pdf_bytes = st.session_state.get("pdf_bytes")
    if not pdf_bytes:
        st.warning("ì—…ë¡œë“œëœ PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("</div>", unsafe_allow_html=True)
        return

    ph = st.empty()
    def cb(info):
        ph.markdown(
            f"<div class='meter'>p.{info.get('page_label')} | í‘œ={info.get('n_tables')} Â· ë‹¨ì–´={info.get('n_words')} {'Â· TOC' if info.get('is_toc') else ''}</div>",
            unsafe_allow_html=True
        )

    with st.spinner("ë¶„ì„ì¤‘..."):
        chunks = build_chunks(pdf_bytes, progress=cb)

    st.session_state["chunks"] = chunks
    st.session_state.setdefault("chat", [])
    st.session_state.setdefault("toc_tab", "ê·¸ë¦¼ ëª©ì°¨")
    st.session_state.setdefault("right_open", True)

    th = _current_thread()
    if th is not None:
        th["chunks"] = chunks
        th["pdf_bytes"] = pdf_bytes

    st.session_state["route"] = "analysis"
    st.rerun()

# ================== ë¶„ì„ í˜ì´ì§€ ==================
def analysis_page():
    st.markdown(f"<style>{get_css()}</style>", unsafe_allow_html=True)
    st.markdown("<style>html, body { overflow: auto !important; }</style>", unsafe_allow_html=True)  # ìŠ¤í¬ë¡¤ ë³µì›

    render_sidebar()

    pdf_bytes = st.session_state.get("pdf_bytes")
    pdf_name  = st.session_state.get("pdf_name") or "ë¶„ì„ ë¬¸ì„œ"
    chunks    = st.session_state.get("chunks") or {}

    st.session_state.setdefault("toc_tab", "ê·¸ë¦¼ ëª©ì°¨")
    st.session_state.setdefault("right_open", True)
    st.session_state.setdefault("chat", [])

    main_col, right_col = st.columns([1, 1], gap="large")

    with main_col:
        st.markdown("<div class='hp-main-sentinel'></div>", unsafe_allow_html=True)
        _render_header(pdf_name, chunks)
        _render_chat_panel(pdf_bytes, chunks)

        ask = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")
        if ask:
            item = _make_item_from_free_query(ask, chunks)
            st.session_state["chat"].append(item)
            _ensure_thread(); _append_to_thread(item)
            st.rerun()

    with right_col:
        st.markdown("<div class='hp-right-sentinel'></div>", unsafe_allow_html=True)
        st.markdown("<div class='hp-right-wrap'>", unsafe_allow_html=True)

        if st.button(("ğŸ“‘ ëª©ì°¨ íŒ¨ë„ ì ‘ê¸°" if st.session_state["right_open"] else "ğŸ“‘ ëª©ì°¨ íŒ¨ë„ ì—´ê¸°"),
                     use_container_width=True, key="toggle-right"):
            st.session_state["right_open"] = not st.session_state["right_open"]
            st.experimental_rerun()

        if st.session_state["right_open"]:
            tab = st.radio("ë³´ê¸°", ["ë¹ ë¥¸ íƒœê·¸", "í‘œ ëª©ì°¨", "ê·¸ë¦¼ ëª©ì°¨"],
                           index=["ë¹ ë¥¸ íƒœê·¸","í‘œ ëª©ì°¨","ê·¸ë¦¼ ëª©ì°¨"].index(st.session_state["toc_tab"]),
                           horizontal=True, label_visibility="collapsed")
            st.session_state["toc_tab"] = tab

            q = ""
            if tab == "í‘œ ëª©ì°¨":
                q = st.text_input("í‘œ ê²€ìƒ‰", key="toc_q_tab", placeholder="ì˜ˆ) ê°€êµ¬, ê°€ê²©, 2023 ...",
                                  label_visibility="collapsed")
            elif tab == "ê·¸ë¦¼ ëª©ì°¨":
                q = st.text_input("ê·¸ë¦¼ ê²€ìƒ‰", key="toc_q_fig", placeholder="ì˜ˆ) ì¶”ì´, ë¹„êµ, 2023 ...",
                                  label_visibility="collapsed")
            else:
                st.caption("ì¶”ì²œ ì§ˆë¬¸(ë¬¸ì¥í˜•)ì„ í´ë¦­í•˜ë©´ ë°”ë¡œ ì§ˆë¬¸ë©ë‹ˆë‹¤.")

            st.markdown("<div class='hp-right-list'>", unsafe_allow_html=True)
            if tab == "ë¹ ë¥¸ íƒœê·¸":
                _right_quick_tags(chunks)
            elif tab == "í‘œ ëª©ì°¨":
                _right_table_list(chunks, q)
            else:
                _right_figure_list(chunks, q)
            st.markdown("</div>", unsafe_allow_html=True)
        else:
            st.caption("ì˜¤ë¥¸ìª½ ëª©ì°¨ íŒ¨ë„ì´ ì ‘í˜€ ìˆìŠµë‹ˆë‹¤.")
        st.markdown("</div>", unsafe_allow_html=True)

# --------- í—¤ë” ----------
def _render_header(pdf_name: str, chunks: Dict[str,Any]):
    n_t = len(chunks.get("tables", []))
    n_f = len(chunks.get("figures", []))
    n_x = len(chunks.get("texts", []))
    try: w_total = sum(len((p.get("text") or "").split()) for p in chunks.get("texts", []))
    except Exception: w_total = 0
    w_k = f"{w_total:,}"

    st.markdown(
        f"""
        <div class="hp-header">
          <div class="title">ğŸ“„ {pdf_name}</div>
          <div class="summary">ë¶„ì„ ì™„ë£Œ Â· ë‹¨ì–´ìˆ˜ {w_k} Â· í…ìŠ¤íŠ¸ {n_x} Â· í‘œ {n_t} Â· ê·¸ë¦¼ {n_f}</div>
        </div>
        <div class="hp-top-spacer"></div>
        """, unsafe_allow_html=True
    )

# --------- ì˜¤ë¥¸ìª½ íŒ¨ë„ ì½˜í…ì¸  / ì±„íŒ… ë Œë” í•¨ìˆ˜ë“¤(ê¸°ì¡´ ê·¸ëŒ€ë¡œ) ----------
def _right_quick_tags(chunks: Dict[str,Any], k:int=18):
    pages = [{"text": p.get("text","")} for p in chunks.get("texts", [])]
    tags = generate_query_tags(pages, k=k) or []
    for i, t in enumerate(tags):
        label = "#" + re.sub(r"\s+", "", t.split()[0])[:12]
        if st.button(label, key=f"rqt-{i}", use_container_width=True):
            ctx = _find_relevant_context(chunks, t)
            item = {"q": t, "kind":"qa"}
            if ctx: item.update({"context":ctx["context"], "context_page":ctx["page"]})
            st.session_state["chat"].append(item)
            _ensure_thread(); _append_to_thread(item)
            st.experimental_rerun()

def _right_table_list(chunks: Dict[str,Any], q: str):
    tabs = chunks.get("toc", {}).get("tables", [])
    for i, t in enumerate(tabs):
        txt = f"<í‘œ {t['label']}> {t['title']}"
        if q and (q not in txt): continue
        if st.button(txt, key=f"rtab-{i}-{t['label']}", use_container_width=True):
            item = {"q": txt, "kind":"table", "label": t["label"]}
            st.session_state["chat"].append(item); _ensure_thread(); _append_to_thread(item); st.experimental_rerun()

def _right_figure_list(chunks: Dict[str,Any], q: str):
    figs = chunks.get("toc", {}).get("figures", [])
    for i, f in enumerate(figs):
        txt = f"[ê·¸ë¦¼ {f['label']}] {f['title']}"
        if q and (q not in txt): continue
        if st.button(txt, key=f"rfig-{i}-{f['label']}", use_container_width=True):
            item = {"q": txt, "kind":"figure", "label": f["label"]}
            st.session_state["chat"].append(item); _ensure_thread(); _append_to_thread(item); st.experimental_rerun()

_IMAGE_MAX = 980
def _render_chat_panel(pdf_bytes: bytes, chunks: Dict[str,Any]):
    for item in st.session_state["chat"]:
        st.markdown("<div class='hp-turn'>", unsafe_allow_html=True)
        st.markdown(f"<div class='hp-msg me'><div class='bubble'>ğŸ™‹ { (item.get('q') or '').strip() }</div></div>", unsafe_allow_html=True)
        kind = item.get("kind")
        if kind == "table":
            t = find_table_by_label(chunks, item.get("label"))
            if not t:
                st.markdown("<div class='hp-msg'><div class='bubble'>í•´ë‹¹ í‘œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.</div></div>", unsafe_allow_html=True)
            else:
                _render_table_item(t, pdf_bytes)
        elif kind == "figure":
            f = find_figure_by_label(chunks, item.get("label"))
            if not f:
                st.markdown("<div class='hp-msg'><div class='bubble'>í•´ë‹¹ ê·¸ë¦¼ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.</div></div>", unsafe_allow_html=True)
            else:
                _render_figure_item(f, pdf_bytes)
        elif kind == "qa":
            ctx = item.get("context", ""); page = item.get("context_page")
            with st.spinner("ê·¼ê±° ë¬¸ë‹¨ìœ¼ë¡œ ë‹µë³€ ìƒì„±ì¤‘..."):
                ans = answer_with_context(item.get("q",""), ctx)
            st.markdown(
                f"<div class='hp-msg'><div class='bubble'>{ans}</div>" +
                (f"<div class='sub'>ê·¼ê±°: p.{page}</div>" if page else "") + "</div>",
                unsafe_allow_html=True
            )
        else:
            st.markdown("<div class='hp-msg'><div class='bubble'>ì˜¤ë¥¸ìª½ 'ëª©ì°¨ íŒ¨ë„'ì´ë‚˜ ë¹ ë¥¸ íƒœê·¸ë¥¼ ì‚¬ìš©í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.</div></div>", unsafe_allow_html=True)

def _render_table_item(t: Dict[str,Any], pdf_bytes: bytes):
    title = (t.get("title") or t.get("caption") or "").strip(); label = t.get("label") or "?"
    st.markdown(f"<div class='hp-msg'><div class='bubble'>'&lt;í‘œ {label}&gt; {title}' í‘œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.</div></div>", unsafe_allow_html=True)
    if t.get("bbox") is not None:
        img = crop_table_image(pdf_bytes, t["page"]-1, t["bbox"], dpi=220); st.image(img, width=_IMAGE_MAX)
    st.markdown(f"<div class='hp-msg'><div class='sub'>ì›ë¬¸ ê·¼ê±°: p.{t['page']}</div></div>", unsafe_allow_html=True)

def _render_figure_item(f: Dict[str,Any], pdf_bytes: bytes):
    title = (f.get("title") or f.get("caption") or "").strip(); label = f.get("label") or "?"
    st.markdown(f"<div class='hp-msg'><div class='bubble'>'[ê·¸ë¦¼ {label}] {title}' ê·¸ë¦¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.</div></div>", unsafe_allow_html=True)
    if f.get("bbox") is not None:
        img = crop_figure_image(pdf_bytes, f["page"]-1, f["bbox"], dpi=220); st.image(img, width=_IMAGE_MAX)
    st.markdown(f"<div class='hp-msg'><div class='sub'>ì›ë¬¸ ê·¼ê±°: p.{f['page']}</div></div>", unsafe_allow_html=True)

def _make_item_from_free_query(q: str, chunks: Dict[str,Any]) -> Dict[str,Any]:
    tab, fig = _parse_labels(q)
    if tab:  return {"q": q, "kind":"table", "label": tab}
    if fig:  return {"q": q, "kind":"figure", "label": fig}
    ctx = _find_relevant_context(chunks, q)
    if ctx:  return {"q": q, "kind":"qa", "context": ctx["context"], "context_page": ctx["page"]}
    return {"q": q, "kind":"none"}

def _parse_labels(q: str) -> Tuple[Optional[str], Optional[str]]:
    m_tab = re.search(r"[<\\[]?\\s*í‘œ\\s*([0-9]+[-â€“][0-9]+)\\s*[>\\]]?", q)
    m_fig = re.search(r"[<\\[]?\\s*ê·¸ë¦¼\\s*([0-9]+[-â€“][0-9]+)\\s*[>\\]]?", q)
    return (m_tab.group(1).replace("â€“","-") if m_tab else None,
            m_fig.group(1).replace("â€“","-") if m_fig else None)

def _find_relevant_context(chunks: Dict[str,Any], q: str) -> Optional[Dict[str,Any]]:
    texts = chunks.get("texts", []); best, best_s, best_page = "", 0.0, None
    ql = (q or "").lower()
    for t in texts:
        for para in re.split(r"\n{2,}", t.get("text") or ""):
            s = _score((para or "").lower(), ql)
            if s > best_s: best_s, best, best_page = s, para, t["page"]
    if best_page:
        ctx = " ".join([ln.strip() for ln in best.splitlines() if ln.strip()][:3])
        return {"context": ctx[:1200], "page": best_page}
    return None

def _score(text: str, ql: str) -> float:
    score = 0.0
    for w in re.findall(r"[ê°€-í£a-z0-9]+", ql):
        if len(w) >= 2 and w in text: score += 1.0
    return score
